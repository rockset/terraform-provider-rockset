---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "rockset_kafka_collection Resource - rockset"
subcategory: ""
description: |-
  Manages a collection created from a Kafka source. The use_v3 field must match the integration which the collection is created from.
---

# rockset_kafka_collection (Resource)

Manages a collection created from a Kafka source. The `use_v3` field must match the integration which the collection is created from.

## Example Usage

```terraform
variable "bootstrap_servers" {
  description = "Confluent Cloud bootstrap servers."
}

variable "apikey" {
  description = "Confluent Cloud API key."
}

variable "secret" {
  description = "Confluent Cloud secret."
}

resource rockset_kafka_integration confluent {
  name = "confluent-cloud"
  description = "Integration to ingest documents from Confluent Cloud"
  use_v3            = true
  bootstrap_servers = var.bootstrap_servers
  security_config = {
    api_key = var.apikey
    secret  = var.secret
  }
}

resource rockset_workspace confluent {
  name = "confluent"
  description = "Collections from Confluent Cloud topics."
}

resource rockset_kafka_collection test {
  name           = "confluent-cloud-collection"
  workspace      = rockset_workspace.confluent.name
  description    = "Collection from a Confluent Cloud topic."
  retention_secs = 3600

  source {
    integration_name = rockset_kafka_integration.confluent.name
    use_v3           = true
    topic_name       = "test_json"
    offset_reset_policy = "EARLIEST"
  }
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `name` (String) Unique identifier for the collection. Can contain alphanumeric or dash characters.
- `workspace` (String) The name of the workspace.

### Optional

- `description` (String) Text describing the collection.
- `ingest_transformation` (String) Ingest transformation SQL query. Turns the collection into insert_only mode.

When inserting data into Rockset, you can transform the data by providing a single SQL query, 
that contains all of the desired data transformations. 
This is referred to as the collectionâ€™s ingest transformation or, historically, its field mapping query.

For more information see https://rockset.com/docs/ingest-transformation/
- `retention_secs` (Number) Number of seconds after which data is purged. Based on event time.
- `source` (Block Set) Defines a source for this collection. (see [below for nested schema](#nestedblock--source))
- `storage_compression_type` (String) RocksDB storage compression type. Possible values: ZSTD, LZ4.
- `timeouts` (Block, Optional) (see [below for nested schema](#nestedblock--timeouts))
- `wait_for_collection` (Boolean) Wait until the collection is ready.
- `wait_for_documents` (Number) Wait until the collection has documents. The default is to wait for 0 documents, which means it doesn't wait.

### Read-Only

- `id` (String) The ID of this resource.

<a id="nestedblock--source"></a>
### Nested Schema for `source`

Required:

- `integration_name` (String) The name of the Rockset Kafka integration.
- `topic_name` (String) Name of Kafka topic to be tailed.

Optional:

- `offset_reset_policy` (String) The offset reset policy. Possible values: LATEST, EARLIEST. Only valid with v3 collections.
- `use_v3` (Boolean) Whether to use v3 integration. Required if the kafka integration uses v3.

Read-Only:

- `consumer_group_id` (String) The Kafka consumer group Id being used.
- `status` (List of Object) (see [below for nested schema](#nestedatt--source--status))

<a id="nestedatt--source--status"></a>
### Nested Schema for `source.status`

Read-Only:

- `documents_processed` (Number)
- `last_consumed_time` (String)
- `partitions` (Set of Object) (see [below for nested schema](#nestedobjatt--source--status--partitions))
- `state` (String)

<a id="nestedobjatt--source--status--partitions"></a>
### Nested Schema for `source.status.partitions`

Read-Only:

- `offset_lag` (Number)
- `partition_number` (Number)
- `partition_offset` (Number)




<a id="nestedblock--timeouts"></a>
### Nested Schema for `timeouts`

Optional:

- `create` (String)
